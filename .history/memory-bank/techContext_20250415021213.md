# Tech Context

## Technologies Used

- **yt-dlp**: For downloading videos, extracting audio, and saving metadata.
- **Python**: Main workflow scripting and orchestration (`transcription_workflow.py`, `src/main.py`).
- **SQLite**: Central database for tracking metadata, status, and text content (`database_manager.py`).
- **OpenAI (via OpenRouter)**: For transcription (Whisper), transcript correction (e.g., Claude 3, GPT-4), and summarization.
- **pyannote.audio**: For speaker diarization (optional, requires setup).
- **PyQt6**: For the GUI (`src/main.py`).
- **dotenv**: For environment variable management.
- **Standard Python libraries**: os, subprocess, logging, re, datetime, json, sqlite3, csv.
- **Streaming Export**: Export logic is designed to handle large datasets efficiently, using streaming/chunked writes to CSV or JSON Lines.

## Development Setup

- Python 3.8+ recommended.
- yt-dlp must be installed and available in the system PATH.
- ffmpeg must be installed and available in the system PATH.
- OpenAI API key (via OpenRouter) must be set in the environment.
- Hugging Face token (`HF_TOKEN`) required for diarization with `pyannote.audio` (if used).
- All scripts are run from the project root; outputs are organized under the specified working directory.

## Technical Constraints

- Video titles with special characters or duplicates may require sanitization for filesystem compatibility.
- The workflow assumes a stable internet connection for downloading and API calls.
- Large playlists or long videos may require additional disk space and processing time.
- Diarization requires `pyannote.audio` dependencies and a Hugging Face token; if not set up, diarization will be skipped.
- ffmpeg is required for audio extraction and conversion.

## Dependencies

- yt-dlp
- openai
- python-dotenv
- PyQt6
- pyannote.audio (optional, for diarization)
- torch (optional, dependency for pyannote.audio)
- pytest, pytest-mock (for testing)
- requests, PyYAML, protobuf (for API/model management)
- sqlite3 (built-in)
- Standard libraries: os, subprocess, logging, re, datetime, json, csv

## Tool Usage Patterns

- `yt-dlp` is called via `subprocess` for fetching playlist info (`--dump-json`), video download (`--write-info-json`), and audio extraction.
- `database_manager.py` (now a `DatabaseManager` class) handles all SQLite operations (initialization, CRUD, querying) using helper methods and dataclasses.
- **Pipeline Execution:** Both CLI and GUI workflows call `DatabaseManager` methods (`add_or_update_video`, `add_transcript`, `add_summary`, `update_video_status`) during the download and processing phases to store results and track status.
- **Data Management:**
    - The CLI (`transcription_workflow.py`) uses arguments (`--status`, `--list-errors`, `--view`, `--retry`, `--delete`) which call corresponding `DatabaseManager` methods (`get_all_video_details`, `get_videos_by_status`, `get_video_details`, `get_video_paths`, `update_video_status`, `delete_video`).
    - The GUI (`src/main.py`) uses a `QTableView` with a custom `QAbstractTableModel` on the "Manage Data" tab. Actions (Refresh, Retry All, context menu) trigger calls to the same `DatabaseManager` methods used by the CLI for viewing, retrying, and deleting data.
- **Data Export:**
    - The CLI uses new arguments (`--export`, `--ids`, `--status_filter`) to trigger calls to `DatabaseManager.export_to_csv` or `export_to_json`.
    - The GUI uses a context menu action ("Export Selected...") which triggers an `ExportThread`. The thread calls the same `DatabaseManager` export methods using selected IDs obtained from the table view.
    - Both interfaces use streaming/chunked export logic in `DatabaseManager` to handle large datasets efficiently and avoid memory constraints.
- Core audio processing (transcription, diarization, correction, summarization) is handled by `workflow_logic.process_audio_file`.
- `pyannote.audio` pipeline is loaded in `workflow_logic.py` for diarization if available.
- OpenAI API (via OpenRouter) is used for transcription (Whisper), correction, and summarization within `workflow_logic.py`.
- The GUI (`src/main.py`) uses a `QThread` to run the download and processing steps, interacting with the database via the `DatabaseManager` instance.
- Improved error handling and logging are implemented throughout, including DB status updates and per-video logs.
