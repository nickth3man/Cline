# Tech Context

## Technologies Used

- **yt-dlp**: For downloading audio from YouTube videos/playlists.
- **Python**: Main workflow scripting and orchestration.
- **OpenRouter API**: For transcription (Whisper) and LLM-based correction/summarization.
  - **Transcription:** Fixed to `openai/whisper-large-v3`.
  - **LLM Correction/Summarization:** User-selectable from all available OpenRouter LLMs (live-fetched), with advanced selection (search, variants, provider routing, model details, error handling).
- **SpaCy**: Required for sentence splitting and text cleanup.
- **pyannote.audio**: For speaker diarization, always performed locally (requires Hugging Face token and setup).
- **dotenv**: For environment variable management.
- **Standard Python libraries**: os, subprocess, logging, re, datetime, json, csv, etc.
- **UI Framework**: (e.g., PyQt6 or web-based) for advanced dropdowns, live price display, error feedback, and user interaction.

## Development Setup

- Python 3.8+ recommended.
- yt-dlp must be installed and available in the system PATH.
- SpaCy must be installed and available.
- pyannote.audio and dependencies must be installed; Hugging Face token required for gated models.
- OpenRouter API key must be set in the environment.
- All scripts are run from the project root; outputs are organized per video.
- All code, UI, and documentation are strictly aligned with OpenRouter's API and best practices.

## Technical Constraints

- Only `openai/whisper-large-v3` is used for transcription (audio-to-text).
- Only SpaCy is used for sentence splitting (no regex fallback).
- LLM correction and summarization models are user-selectable from all OpenRouter LLMs, fetched live, with advanced selection and error handling.
- pyannote.audio must be set up locally for diarization; requires a Hugging Face token and model downloads.
- OpenRouter API costs for transcription and LLM steps depend on audio length and model selection; UI must display real-time price estimates and surface all errors.
- Large playlists or long videos may require significant disk space, compute, and API usage.

## Dependencies

- yt-dlp
- openai (for OpenRouter API)
- python-dotenv
- SpaCy
- pyannote.audio
- torch (for pyannote.audio)
- requests (for OpenRouter model fetching)
- UI framework (e.g., PyQt6, web)
- Standard libraries: os, subprocess, logging, re, datetime, json, csv

## Tool Usage Patterns

- **Audio Download:** yt-dlp downloads audio to per-video folders.
- **Transcription:** OpenRouter Whisper is called via API for all audio-to-text.
- **Sentence Splitting:** SpaCy processes all transcripts for sentence segmentation and cleanup.
- **LLM Correction/Summarization:** UI fetches all available OpenRouter LLMs live; user selects model for each step; UI supports advanced selection (search, variants, provider routing, model details) and calculates/displays estimated cost in real time.
- **Diarization:** pyannote.audio runs locally on each audio file; outputs diarization.json per video.
- **Output:** All results are saved per video, with clear naming and structure.
- **Error Handling:** Errors are logged per video, surfaced in the GUI, and the pipeline continues processing other videos.
- **Extensibility:** The architecture is modular and ready for future OpenRouter features and advanced model selection.
