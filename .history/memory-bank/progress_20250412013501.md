# Progress

## Current Status

- The core workflow for downloading, audio extraction, transcription, diarization, correction, and summarization is implemented in `workflow_logic.py`.
- The file structure and organization meet the requirements.
- Improved error handling and logging have been implemented.
- Metadata extraction using `yt-dlp --write-info-json` has been added.
- Speaker diarization (using `pyannote.audio`) and LLM-based transcript correction are integrated into the core processing logic used by both the GUI (`src/main.py`) and the CLI (`transcription_workflow.py`).
- **SQLite Database Integration:** A central database (`pipeline_output.db`) now tracks video metadata, processing status, file paths, transcript content, and summary content. Both GUI and CLI workflows interact with this database.
- **Database Management Features:** Both the CLI and GUI now include features to view status, list errors, view details, retry failed items, and delete video records (with optional file deletion).
- **Summarization Re-enabled:** Summarization is now part of the core processing pipeline (`workflow_logic.py`), results are stored in the database (`summaries` table), and both CLI and GUI allow selection of the summarization model.
- **Data Export Feature:** Added functionality to export data (metadata, transcript, summary) from the database to CSV or JSON Lines format via both the CLI (`--export`, `--ids`, `--status`) and GUI (context menu on "Manage Data" tab). Export uses streaming to handle large datasets.

## Remaining Tasks

- Review and update all memory bank documentation (**In Progress - Updating for Export Feature**).
- Confirm that the workflow meets all user requirements and is robust for future scaling (**Final Step**).
- Detailed Workflow Design & Implementation:
  - Design and implement audio handling/extraction logic (using `ffmpeg` if needed).
  - Implement specific API call logic for OpenRouter STT (Whisper endpoint).
  - Develop and test prompts for LLM calls (term extraction, correction, speaker mapping) via OpenRouter. Implement API call logic, including handling structured output for term extraction.
  - Implement `pyannote.audio` integration for local diarization, including model loading and processing.
  - Develop the Python script for merging corrected text, diarization results, and speaker names (if mapped), and formatting the final output (e.g., Markdown).
  - Structure the code (e.g., single script vs. modules).
  - (Consider adding retry logic for transient failures)
- **`ffmpeg` Dependency:** Investigate and clarify if `ffmpeg` is needed for audio preparation for the STT API or `pyannote.audio`. Implement necessary calls if required.
- **GUI Refinements:**
  - Consider adding more granular progress (e.g., download percentage).
  - Improve layout resizing.
  - Potentially add more detailed logging display within the GUI.
- **Testing & Iteration:** Test the complete workflow, refine prompts, address accuracy issues.
- **Documentation:** Document setup, usage, and configuration.

## Known Issues

- Speaker diarization requires `pyannote.audio` dependencies to be installed and potentially a Hugging Face token (`HF_TOKEN`) to be configured in the environment. If not set up, diarization will be skipped.
- Potential reliance on `ffmpeg` being installed is not explicitly handled or checked. Errors might occur if it's needed and isn't present.
- Effectiveness of specific LLMs via OpenRouter for the workflow tasks needs testing. Prompt engineering is key.
- User noted potential issues with `pyannote` when speakers overlap; this might remain a manual correction point or require advanced configuration/post-processing.

## Evolution of Decisions

- Project scope defined based on user's detailed description.
- Core constraint identified: use of a single OpenRouter API key.
- **Initial STT approach confirmed: Use Whisper API via OpenRouter endpoint.** (Replaced local Whisper idea to meet constraint).
- **OpenRouter API Key Provided.**
