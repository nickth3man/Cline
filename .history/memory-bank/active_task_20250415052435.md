# Current Task

**Test the full pipeline using the provided YouTube playlist with fixed output directory**

- Download all videos from: https://www.youtube.com/playlist?list=PLTSh1Wa3gjplaOdhzJzzv6Tzh3KbiZsrX
- Use fixed output directory: `output/` (no option to change)
- For each video:
    - Transcribe (OpenAI Whisper API, not OpenRouter; requires OPENAI_API_KEY)
    - Sentence split (SpaCy)
    - LLM correction & summarization (OpenRouter, test multiple models; requires OPENROUTER_API_KEY)
    - Pseudo-diarization: Use OpenRouter LLM to infer and assign speaker labels to the transcript after transcription, based on context and timestamps (no Hugging Face/pyannote required)
    - Generate all outputs (audio, transcripts, summaries, metadata, HTML reader)
- Validate outputs and log results.
- Update documentation and memory bank with findings.

**Note:** OpenRouter does not provide a Whisper (audio transcription) API endpoint. The pipeline uses the official OpenAI API for transcription and OpenRouter for all LLM-based tasks.
